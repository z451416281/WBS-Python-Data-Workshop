{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Stacking\n", "\n", "In this notebook, you will see how to use stacking in a reasonably straightforward manner; stacking can really quickly become quite computationally expensive.\n", "\n", "Note that stacking may sometime not help to improve the performances of your model overall, just like in the rest of Data Science / Machine Learning, there isn't the \"one magic recipe\", just a number of good tools that may or may not work for your problem!\n", "\n", "## The data\n", "\n", "Our dataset corresponds to a set of attributes for customers of an online retail website and whether the customer returned to the shop after their purchases were recorded. We want to predict if the customer will return or not."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the dataset from `data/online_retail.csv`. You will need to set the column `CustomerID` as index. Display the dataset with `.head()`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["The column `has_returned` needs to be converted to integer: convert False to 0 and True to 1:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Get X and y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Use `train_test_split` from `sklearn.model_selection` to create X_train, X_test, y_train and y_test:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Baseline RF classifier\n", "\n", "To get a quick baseline, apply a RF classifier with default setting (set `random_state=0` so that everyone gets the same results) and use the `classification_report` to investigate how well the model is doing (don't forget to import the relevant libraries)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# your code here to fit a RF classifier\n", "\n", "# your code here to display a report on the model\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Stacking classifiers\n", "\n", "Here you are going to use `mlxtend` (which you can install easily via `pip`). \n", "\n", "The key class in the library that you will use is `StackingCVClassifier` from `mlxtend.classifier`. You can look up [the documentation](http://rasbt.github.io/mlxtend/) to review the API but the basic usage is of the form:\n", "\n", "```python\n", "stack = StackingCVClassifier(classifiers=[clf1, clf2, clf3],\n", "                             meta_classifier = clfmeta,\n", "                             use_probas=True,\n", "                             use_clones=False\n", "                             cv=5)\n", "```\n", "\n", "Where `classifiers` takes a list of SkLearn classifiers, `meta_classifier` is the classifier used at the higher level, use probas allow us to use the probabilities outputed by base classifiers instead the classes, that should provide more granular information for our meta learner to learn from. `use_clones` is set so that the stack uses the instance of the classifiers we provide instead of working on a copy (so that we can easily access individual classifiers). Finally `cv` is the number of cross validation folds to use to train the model.\n", "\n", "In this example, consider two base classifiers:\n", "\n", "* KNN (with 2 neighbors)\n", "* RF (with 100 estimators)\n", "\n", "and as a secondary classifier, consider a decision tree with a depth of 4 (a simple tree should be enough since we only have two features here, the output of the previous classifiers)\n", "\n", "Train the stack using the usual `sklearn` way (`mlxtend` implements `fit` and `predict` just like `Sklearn`) and show the classification report, compare with what you had before. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# import the relevant libraries\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# define the classifiers\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# fit the stack and show the results\n", "# you might have to pass X and y as numpy array\n", "# as mlxtend can struggle with pandas DataFrame\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Cross validating a stack\n", "\n", "`StackingCVClassfier` is built-in with it's own cross validation. Meaning that for a given training set, it will run cross validation under the hood to fit the meta learner on data generated from predictions on a part of the dataset that wasn't used to train the first layer. Hence we have confidence that our model will be properly trained.\n", "\n", "Now in order to compare hyperparameters, we still need to run cross-validation on top of it, so we don't choose parameters that simply do well on a specific train set that we have. To do so we can use `GridSearchCV` as we usually do. The key difference is that you have to pay attention to how parameters are named. The convention is:\n", "\n", "```\n", "nameofclassifier__parameter\n", "meta-nameofclassifier__parameter\n", "```\n", "\n", "For example:\n", "\n", "* `kneighborsclassifier__n_neighbors`\n", "\n", "You can get the list of names given to your classifiers by checking the attributes `named_meta_classifier` and `named_classifiers` on your stacking object.\n", "\n", "The parameters you may want to tune are:\n", "\n", "* number of neighbors for the KNN\n", "* max_depth and min_samples_split of random forest\n", "* max_depth of meta classifier\n", "\n", "(watch out this may take some time)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# add your code for GCV\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What are your best parameters?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Retrain your stack with those parameters. You can use `set_params` to set the parameters of the different models in your stack"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Check the classification report:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# add your code here\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Plotting the meta learner (Decision Tree)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.display import Image  \n", "from sklearn import tree\n", "import pydotplus\n", "\n", "dot_data = tree.export_graphviz(stack.meta_classifier, \n", "                                out_file=None, \n", "                                filled=True, \n", "                                rounded=True,\n", "                                proportion=True,\n", "                                special_characters=True,\n", "                               feature_names=[\"RF_P0\", \"RF_P1\", \"KNN_P0\", \"KNN_P1\"])\n", "\n", "graph = pydotplus.graph_from_dot_data(dot_data)  \n", "Image(graph.create_png())"]}]}