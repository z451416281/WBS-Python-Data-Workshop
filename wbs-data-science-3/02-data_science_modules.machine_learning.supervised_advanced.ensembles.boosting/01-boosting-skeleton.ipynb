{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Boosting - Gradient Boosting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Note**: If you have completed the Decision Tree or Random Forest notebooks already, those preprocessing steps are the same. Feel free to copy paste answers from the previous notebook or the solutions and jump straight to the Gradient Boosting part."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### The Dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The dataset can be downloaded [here](https://archive.ics.uci.edu/ml/datasets/bank+marketing). It consists of data from marketing campaigns of a Portuguese bank. We will try to build a classifier that can predict whether or not the client targeted by the campaign ended up subscribing to a term deposit (column `y`).\n", "\n", "Load the file `data/bank-marketing.zip` with pandas and check the distribution of the target `y`. Here the separator is `';'` instead of a comma."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["The dataset is imbalanced, we will need to keep that in mind when building our models!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now split the data into the feature matrix `X` (all features except `y`) and the target vector `y` making sure that you convert `yes` to `1` and `no` to `0`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Get X, y\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here is the list of features in our X matrix:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["```\n", "1. age (numeric)\n", "2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n", "3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n", "4. education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n", "5. default: has credit in default? (categorical: 'no','yes','unknown')\n", "6. housing: has housing loan? (categorical: 'no','yes','unknown')\n", "7. loan: has personal loan? (categorical: 'no','yes','unknown')\n", "8. contact: contact communication type (categorical: 'cellular','telephone') \n", "9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n", "10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n", "11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n", "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n", "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n", "14. previous: number of contacts performed before this campaign and for this client (numeric)\n", "15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n", "16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n", "17. cons.price.idx: consumer price index - monthly indicator (numeric) \n", "18. cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n", "19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n", "20. nr.employed: number of employees - quarterly indicator (numeric)\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note the comment about the `duration` feature. We will exclude it from our analysis.\n", "\n", "Drop `duration` from X:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can check the types of all our features. We see that some seem to be categorical whilst others are numerical. We will keep a two lists, one for each type, so we can preprocess them differently."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["X.dtypes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# they have a third class \"unknown\" we'll process them as non binary categorical\n", "num_features = [\"age\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \n", "                \"cons.price.idx\", \"cons.conf.idx\",\"euribor3m\", \"nr.employed\"]\n", "\n", "cat_features = [\"job\", \"marital\", \"education\",\"default\", \"housing\", \"loan\",\n", "                \"contact\", \"month\", \"day_of_week\", \"poutcome\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualise the numerical features\n", "\n", "* show a boxplot of the numerical features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["The features aren't at the same scale. But it's all fine for tree based methods as we've seen in the course, so we do not need to do any scaling here!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### One Hot Encoding on Categorical Features"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In order to make sure our dataset contains only number we will need to transform our categorical features into one hot encoded features. To do so, first, use `pd.get_dummies` on your dataframe (select only the categorical features) to generate the new columns. Assign the new dataframe to a variable `X_categorical`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Create, now we can create `X_processed` using `pd.concat` (check the documentation, you will need to specify the right axis). Here we want to concatenate a dataframe with only our numerical features together with our `X_categorical` we created above:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Split data into training set and test set"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split your data (use `X_processed`) into training and test set. Here we are dealing with an imbalanced dataset, so it is important to enforce stratification. We will use the argument `stratify` from `train_test_split` to do so (check the documentation)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Great, we're ready to start training our Gradient Boosting algorithms!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##  Gradient Boosting"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`Gradient Boosting` is a bit different than other standard algorithms for which sklearn offers a standard implementation and usually people would stick to it. Here there are many optimisations that can make gradient boosting more performant, in terms of machine learning but also software, hence we find multiple good implementations of the algorithms. The most popular boosting libraries are `xgboost`, `lightgbm` and `catboost`. It is unclear which one is `The Best` but they all offer an API following the sklearn API, which means you can easily swap a library for another by simply importing the right class. \n", "\n", "In this notebook we will focus on `xgboost` and `lightgbm`. \n", "\n", "Note: `sklearn` has an implementation of Gradient Boosting, `GradientBoostingClassifier` that you can import from `sklearn.ensemble`. It happens to be slow to train usually and not as performant as the other libraries, but has the advantage of using the same `DecisionTree` class from sklearn and give us access to it, so it can be a good choice if you want to debug your models relying on methods available on Decision Trees"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## XGBoost"]}, {"cell_type": "markdown", "metadata": {}, "source": ["XGBoost has an implementation of gradient boosting that has the same API as sklearn. Hence we can use it later inside `GridSearchCV` as we've done before with sklearn algorithm. For that you can import the `XGBClassifier` from `xgboost.sklearn`\n", "\n", "Here are the main parameters we will want to tune for XGBoost, with the values we will start with:\n", "\n", "- max_depth=15\n", "- min_child_weight=1\n", "- n_estimators=20\n", "\n", "\n", "- subsample=1.\n", "- colsample_bytree=1.\n", "- learning_rate=1.\n", "\n", "XGBoost has a way to give more weight to the minority class as well. It does not compute automatically the right weight though, we need to explicitly pass it. Check the documentation for the parameter `scale_pos_weight` and assign it to the right value:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Train your model on the training set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Check the accuracy of your model both on the training set and test set. Also check the classification report on the test set. \n", "\n", "You can import those functions from `sklearn.metrics`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["What do you observe?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here our model seems to overfit a lot. That's because our trees are two complex **AND/OR** we are building too many of them for the given learning rate we have (remember that the model is built sequentially, and every new tree corrects the error of the previous one, the amplitude of the correction is given by the learning rate)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's add more constraints on our tree and see what it changes.\n", "\n", "Set `max_depth`=7 and `min_child_weight`=5. You can use `set_params` on your model to overwrite parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Re-train your model and check accuracy on both train and test set as well as the classification report on the test set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Right, it looks like for those simple trees and at the given learning rate, we do not overfit anymore. Let's try to add more trees and see what happens.\n", "\n", "Set `n_estimators` to 100 (yes, that's probably too much):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Re-train and measure accuracy and classification report again:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Looks like we are overfitting again... Now are trees not that complicated (not too much variance), but still by adding too many of them our model start to overfit. It's an important thing to keep in mind: for a given learning rate, we will need to find the best constraints on the tree and the best number of tree **together**, the best number of trees will depend on how complex our trees are.\n", "\n", "We can \"easily\" do so by using grid search.\n", "\n", "Create a new gridSearchCV object that finds the best combination of `max_depth`, `min_child_weight` and `n_estimators`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["What are your best parameters:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Re-train your model with the given parameters and check accuracy and classification report:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["There are two other important parameters that we haven't tuned so far:\n", "\n", "- `subsample` that defines the ratio of rows to use for each different tree\n", "- `colsample_bytree` that defines the ratio of columns to use for each different tree\n", "\n", "Those two parameters allow us to force our trees to learn different things in the data and thus can provide a boost in accuracy. Ideally we would tune them together with the other parameters, but that would require much more computations, so here we will tune them given the best parameters we already found.\n", "\n", "Create a new grid search that will find the best combination of `subsample` and `colsample_bytree`. Both are expressed as ratio (between 0 and 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["What are your best parameters:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Re-train your model with the given parameters and check accuracy and classification report:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Great. The last parameter that we haven't changed is the learning rate. Here a lower learning rate will give us more granularity whilst correcting the error, meaning that it will take more trees but we hope to get a better accuracy before we start to overfit. \n", "\n", "Ideally when decreasing the learning rate we would re-tune all parameters, but here we are taking shortcuts and assume the best parameters for our trees are still valid and focus only on getting the new number of trees right:\n", "\n", "Set `learning_rate` to .1 and run a grid search with different values of `n_estimators` to find the new best number of trees:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["What is your best `n_estimators`?:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Re-train your model with the given parameters and check accuracy and classification report:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Plot feature importance"]}, {"cell_type": "markdown", "metadata": {}, "source": ["XGBoost is built-in with a function to plot the importance of your features. Although for boosting that is a more unstable metric since we cannot simply average feature importance over trees (because only the first tree is actually meant to model the initial data). So take it with a pinch of salt!\n", "\n", "Import `plot_importance` from xgboost and pass you XGBClassifier model to it"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Using LightGBM"]}, {"cell_type": "markdown", "metadata": {}, "source": ["LightGBM is a more recent boosting libraries, released by Microsoft. It provides a sklearn API that allow us to easily use it within a Pipeline object.\n", "\n", "Note: LightGBM has a way to handle categorical features, unfortunately this isn't possible with the sklearn API and requires using the more complex training API, which isn't compatible with sklearn. It has the added advantage of handling categorical features, meaning we do not need to use one hot encoding. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a new `LGBMClassifier`. You can import it directly from `lightgbm` and keep the default parameters for now, apart for:\n", "- `class_weight` which allows us to take the inbalance into account, set it to `balanced`\n", "- `subsample` set it to .8\n", "- `colsample_bytree` set it to .8"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "Train it and check accuracy and classification report:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Nice,let's try to tune it now. \n", "\n", "Create a new grid search to find the best combination of `max_depth`, `n_estimators`, `min_child_samples`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["What are your best parameters?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Re-train your model with the given parameters and check accuracy and classification report:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Here again we could tune `subsample`, `colsample_bytree` and decrease the `learning_rate`, but for the purpose of this notebook we can stop here. A last thing we can do though, is checking the feature importance:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import lightgbm\n", "\n", "plt.figure(figsize=(20, 10))\n", "lightgbm.plot_importance(lgb, ax=plt.gca())"]}]}