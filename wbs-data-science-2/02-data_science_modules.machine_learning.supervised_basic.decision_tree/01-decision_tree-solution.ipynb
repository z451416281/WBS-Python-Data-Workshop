{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Decision trees"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### The Dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The dataset can be downloaded [here](https://archive.ics.uci.edu/ml/datasets/bank+marketing). It consists of data from marketing campaigns of a Portuguese bank. We will try to build a classifier that can predict whether or not the client targeted by the campaign ended up subscribing to a term deposit (column `y`).\n", "\n", "Load the file `data/bank-marketing.zip` with pandas and check the distribution of the target `y`. Here the separator is `';'` instead of a comma."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"data/bank-marketing.zip\", sep=\";\")\n", "df.y.value_counts()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The dataset is imbalanced, we will need to keep that in mind when building our models!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now split the data into the feature matrix `X` (all features except `y`) and the target vector `y` making sure that you convert `yes` to `1` and `no` to `0`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Get X, y\n", "y = df[\"y\"].map({\"no\":0, \"yes\":1})\n", "X = df.drop(\"y\", axis=1)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here is the list of features in our X matrix:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["```\n", "1. age (numeric)\n", "2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n", "3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n", "4. education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n", "5. default: has credit in default? (categorical: 'no','yes','unknown')\n", "6. housing: has housing loan? (categorical: 'no','yes','unknown')\n", "7. loan: has personal loan? (categorical: 'no','yes','unknown')\n", "8. contact: contact communication type (categorical: 'cellular','telephone') \n", "9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n", "10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n", "11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n", "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n", "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n", "14. previous: number of contacts performed before this campaign and for this client (numeric)\n", "15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n", "16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n", "17. cons.price.idx: consumer price index - monthly indicator (numeric) \n", "18. cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n", "19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n", "20. nr.employed: number of employees - quarterly indicator (numeric)\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note the comment about the `duration` feature. We will exclude it from our analysis.\n", "\n", "Drop `duration` from X:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X.drop(\"duration\", inplace=True, axis=1)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can check the types of all our features. We see that some seem to be categorical whilst others are numerical. We will keep a two lists, one for each type, so we can preprocess them differently."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["X.dtypes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# they have a third class \"unknown\" we'll process them as non binary categorical\n", "num_features = [\"age\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \n", "                \"cons.price.idx\", \"cons.conf.idx\",\"euribor3m\", \"nr.employed\"]\n", "\n", "cat_features = [\"job\", \"marital\", \"education\",\"default\", \"housing\", \"loan\",\n", "                \"contact\", \"month\", \"day_of_week\", \"poutcome\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualise the numerical features\n", "\n", "* show a boxplot of the numerical features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 10))\n", "sns.boxplot(data=X[num_features], ax=plt.gca())\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The features aren't at the same scale. But it's all fine for tree based methods as we've seen in the course, so we do not need to do any scaling here!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### One Hot Encoding on Categorical Features"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In order to make sure our dataset contains only number we will need to transform our categorical features into one hot encoded features. To do so, first, use `pd.get_dummies` on your dataframe (select only the categorical features) to generate the new columns. Assign the new dataframe to a variable `X_categorical`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_categorical = pd.get_dummies(X[cat_features])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create, now we can create `X_processed` using `pd.concat` (check the documentation, you will need to specify the right axis). Here we want to concatenate a dataframe with only our numerical features together with our `X_categorical` we created above:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_processed = pd.concat([X[num_features], X_categorical], axis=1)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Split data into training set and test set"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split your data (use `X_processed`) into training and test set. Here we are dealing with an imbalanced dataset, so it is important to enforce stratification. We will use the argument `stratify` from `train_test_split` to do so (check the documentation)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=.3, random_state=42, stratify=y)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train a Decision Tree\n", "\n", "Now that we have our preprocessor and our data ready, we can train an decision tree on it. For that we can use a `DecisionTreeClassifier` from `sklearn.tree`\n", "\n", "For now we will keep our tree unconstrained with:\n", "- `max_depth`=None, \n", "- `min_samples_split`=2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "Create a new decision tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n", "\n", "dtc = DecisionTreeClassifier(max_depth=None, min_samples_split=2)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now fit your model on the training set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Execute the cell below to display your tree in the notebook, what do you observe?\n", "\n", "Note: if you get an error about `pydotplus` or `graphviz`, try to run the following code in your terminal:\n", "\n", "```\n", "conda install python-graphviz\n", "conda install -c conda-forge pydotplus\n", "```"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.display import Image  \n", "from sklearn import tree\n", "import pydotplus\n", "\n", "dot_data = tree.export_graphviz(dtc, \n", "                                out_file=None, \n", "                                filled=True, \n", "                                rounded=True,\n", "                                max_depth=6,\n", "                                proportion=True,\n", "                                special_characters=True, feature_names=X_train.columns)\n", "\n", "graph = pydotplus.graph_from_dot_data(dot_data)  \n", "Image(graph.create_png())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute the accuracy of your model on the training data and then on the test data, what can you tell?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\n", "\n", "print(accuracy_score(y_train, dtc.predict(X_train)))\n", "print(accuracy_score(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's investigate a bit more by looking at the `classification_report` (you can import it from `sklearn.metrics`). That will provide us with more information about precision and recall on both our classes."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import classification_report\n", "\n", "print(classification_report(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It looks like our model is predicting the majority class `0` (no) really well, which leads to a high accuracy, but we're really bad at predicting the class `1`, which corresponds to successful campaigns, and is of interest here!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["At this stage we've found two major issues with our model:\n", "\n", "- It largely overfits\n", "- It focuses on the majority class"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With our decision tree, we can address both. \n", "\n", "- For the first one we will need to tune `max_depth` and `min_samples_split`. \n", "- For the second one, we will set `class_weight='balanced'` so that it automatically gives more weight on our minority class as a way to compensate."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's use more sensible/constraining values for `max_depth` and `min_samples_split`, let's say `6` and `20` respectively. To change the parameters of your tree, you can use `set_params` on it with the name and values you want to update (for example `max_depth=6`)\n", "\n", "Don't forget to re-train the tree after instanciating it."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dtc.set_params(max_depth=6, min_samples_split=20)\n", "dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Right let's try to train it again and check the accuracy first (both train and test sets), is it better?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\n", "\n", "print(accuracy_score(y_train, dtc.predict(X_train)))\n", "print(accuracy_score(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can also visualise our tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.display import Image  \n", "from sklearn import tree\n", "import pydotplus\n", "\n", "dot_data = tree.export_graphviz(dtc, \n", "                                out_file=None, \n", "                                filled=True, \n", "                                rounded=True,\n", "                                max_depth=6,\n", "                                proportion=True,\n", "                                special_characters=True, feature_names=X_train.columns)  \n", "\n", "graph = pydotplus.graph_from_dot_data(dot_data)  \n", "Image(graph.create_png())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["That's a simpler tree!\n", "\n", "Let's take a look at the classification report now:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dtc.fit(X_train, y_train)\n", "print(classification_report(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Still doing really badly on the class `1`. Try to set the parameter `class_weight` to `balanced` and retrain your tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dtc.set_params(class_weight=\"balanced\")\n", "dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check the classification report again:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["That's much better!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Use Grid Search to find the optimal parameters"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now that we've observed the impact of various parameters, we can trigger a grid search to find the optimal ones.\n", "\n", "Define a new `parameters` dictionary that contains all the values you want to try for `max_depth` and `min_samples_split`. Then define a new `GridSearchCV` object and find the best parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import GridSearchCV\n", "\n", "parameters  = [{'max_depth': [3, 4, 7], \"min_samples_split\": [5, 10, 20]}] \n", "\n", "gridCV = GridSearchCV(dtc, parameters, cv=10, n_jobs=-1)\n", "\n", "gridCV.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What are you best parameters?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gridCV.best_params_\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great, now we can re-train our model using those parameters. Set the parameters of your tree to be the best ones given by the grid search, and train your model again:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dtc.set_params(**gridCV.best_params_)\n", "dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display your final tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.display import Image  \n", "from sklearn import tree\n", "import pydotplus\n", "\n", "dot_data = tree.export_graphviz(dtc, \n", "                                out_file=None, \n", "                                filled=True, \n", "                                rounded=True,\n", "                                max_depth=6,\n", "                                proportion=True,\n", "                                special_characters=True, feature_names=X_train.columns)\n", "\n", "graph = pydotplus.graph_from_dot_data(dot_data)  \n", "Image(graph.create_png())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute it's accuracy on train and test set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\n", "\n", "print(accuracy_score(y_train, dtc.predict(X_train)))\n", "print(accuracy_score(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally check the classification report:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Plot feature importance"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Decision Trees have the advantage of providing a feature importance, a score allowing you to rank all features by their importance for your model when predicting the outcome. With sklearn, you can access it with the attribute `feature_importances_`.\n", "\n", "Take a look at the `feature_importances_` attribute:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dtc.feature_importances_\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["That's hard to read. The array gives a number for each column in our training set, in the same order. A better way to visualise it would be to put it in a table, let's do that.\n", "\n", "Create a new dataframe where the data is the feature importances you saved above, and the index will be the list of columns from our training data:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["importances_df = pd.DataFrame(dtc.feature_importances_, columns=[\"importance\"], index=X_train.columns)\n", "importances_df.sort_values(\"importance\", ascending=False).head()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot it as a bar plot:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["importances_df.sort_values(\"importance\", ascending=False).plot(kind=\"bar\", figsize=(20,7))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What's your more important feature?"]}]}